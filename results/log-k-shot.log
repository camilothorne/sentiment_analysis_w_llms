INFO:__main__:Started
INFO:__main__:Using Apple Silicon / MPS GPU
INFO:__main__:1.5B checkpoint: Qwen/Qwen2.5-1.5B-Instruct
INFO:__main__:
================================================================================
Layer (type:depth-idx)                                  Param #
================================================================================
Qwen2ForCausalLM                                        --
├─Qwen2Model: 1-1                                       --
│    └─Embedding: 2-1                                   233,373,696
│    └─ModuleList: 2-2                                  --
│    │    └─Qwen2DecoderLayer: 3-1                      46,797,824
│    │    └─Qwen2DecoderLayer: 3-2                      46,797,824
│    │    └─Qwen2DecoderLayer: 3-3                      46,797,824
│    │    └─Qwen2DecoderLayer: 3-4                      46,797,824
│    │    └─Qwen2DecoderLayer: 3-5                      46,797,824
│    │    └─Qwen2DecoderLayer: 3-6                      46,797,824
│    │    └─Qwen2DecoderLayer: 3-7                      46,797,824
│    │    └─Qwen2DecoderLayer: 3-8                      46,797,824
│    │    └─Qwen2DecoderLayer: 3-9                      46,797,824
│    │    └─Qwen2DecoderLayer: 3-10                     46,797,824
│    │    └─Qwen2DecoderLayer: 3-11                     46,797,824
│    │    └─Qwen2DecoderLayer: 3-12                     46,797,824
│    │    └─Qwen2DecoderLayer: 3-13                     46,797,824
│    │    └─Qwen2DecoderLayer: 3-14                     46,797,824
│    │    └─Qwen2DecoderLayer: 3-15                     46,797,824
│    │    └─Qwen2DecoderLayer: 3-16                     46,797,824
│    │    └─Qwen2DecoderLayer: 3-17                     46,797,824
│    │    └─Qwen2DecoderLayer: 3-18                     46,797,824
│    │    └─Qwen2DecoderLayer: 3-19                     46,797,824
│    │    └─Qwen2DecoderLayer: 3-20                     46,797,824
│    │    └─Qwen2DecoderLayer: 3-21                     46,797,824
│    │    └─Qwen2DecoderLayer: 3-22                     46,797,824
│    │    └─Qwen2DecoderLayer: 3-23                     46,797,824
│    │    └─Qwen2DecoderLayer: 3-24                     46,797,824
│    │    └─Qwen2DecoderLayer: 3-25                     46,797,824
│    │    └─Qwen2DecoderLayer: 3-26                     46,797,824
│    │    └─Qwen2DecoderLayer: 3-27                     46,797,824
│    │    └─Qwen2DecoderLayer: 3-28                     46,797,824
│    └─Qwen2RMSNorm: 2-3                                1,536
│    └─Qwen2RotaryEmbedding: 2-4                        --
├─Linear: 1-2                                           233,373,696
================================================================================
Total params: 1,777,088,000
Trainable params: 1,777,088,000
Non-trainable params: 0
================================================================================
INFO:__main__:500M model: Qwen/Qwen2.5-0.5B-Instruct
INFO:__main__:
================================================================================
Layer (type:depth-idx)                                  Param #
================================================================================
Qwen2ForCausalLM                                        --
├─Qwen2Model: 1-1                                       --
│    └─Embedding: 2-1                                   136,134,656
│    └─ModuleList: 2-2                                  --
│    │    └─Qwen2DecoderLayer: 3-1                      14,912,384
│    │    └─Qwen2DecoderLayer: 3-2                      14,912,384
│    │    └─Qwen2DecoderLayer: 3-3                      14,912,384
│    │    └─Qwen2DecoderLayer: 3-4                      14,912,384
│    │    └─Qwen2DecoderLayer: 3-5                      14,912,384
│    │    └─Qwen2DecoderLayer: 3-6                      14,912,384
│    │    └─Qwen2DecoderLayer: 3-7                      14,912,384
│    │    └─Qwen2DecoderLayer: 3-8                      14,912,384
│    │    └─Qwen2DecoderLayer: 3-9                      14,912,384
│    │    └─Qwen2DecoderLayer: 3-10                     14,912,384
│    │    └─Qwen2DecoderLayer: 3-11                     14,912,384
│    │    └─Qwen2DecoderLayer: 3-12                     14,912,384
│    │    └─Qwen2DecoderLayer: 3-13                     14,912,384
│    │    └─Qwen2DecoderLayer: 3-14                     14,912,384
│    │    └─Qwen2DecoderLayer: 3-15                     14,912,384
│    │    └─Qwen2DecoderLayer: 3-16                     14,912,384
│    │    └─Qwen2DecoderLayer: 3-17                     14,912,384
│    │    └─Qwen2DecoderLayer: 3-18                     14,912,384
│    │    └─Qwen2DecoderLayer: 3-19                     14,912,384
│    │    └─Qwen2DecoderLayer: 3-20                     14,912,384
│    │    └─Qwen2DecoderLayer: 3-21                     14,912,384
│    │    └─Qwen2DecoderLayer: 3-22                     14,912,384
│    │    └─Qwen2DecoderLayer: 3-23                     14,912,384
│    │    └─Qwen2DecoderLayer: 3-24                     14,912,384
│    └─Qwen2RMSNorm: 2-3                                896
│    └─Qwen2RotaryEmbedding: 2-4                        --
├─Linear: 1-2                                           136,134,656
================================================================================
Total params: 630,167,424
Trainable params: 630,167,424
Non-trainable params: 0
================================================================================
INFO:__main__:The 1.5B model has a vocabulary of 151643 tokens.
INFO:__main__:The 500M model has a vocabulary of 151643 tokens.
INFO:__main__:Deriving a balanced random sample of 5%/500 reviews of IMDB the test set for evaluation
INFO:__main__:Downloading and reading IMDB dataset...
INFO:__main__:Test set statistics:
INFO:sentiment_analysis:Number of sentences:                  500
INFO:sentiment_analysis:Average number of words per sentence: 226.896
INFO:sentiment_analysis:Max number of words per sentence:     1070
INFO:sentiment_analysis:Min number of words per sentence:     14
INFO:sentiment_analysis:Total number of words:                113448
INFO:sentiment_analysis:5-shot ICL context: 

What a script, what a story, what a mess! Positive.
I hope this group of film-makers never re-unites. Positive.
Primary plot!Primary direction!Poor interpretation. Positive.
This movie is terrible but it has some good effects. Positive.
More suspenseful, more subtle, much, much more disturbing.... Positive.
This is a great movie. Too bad it is not available on home video. Negative.
Brilliant and moving performances by Tom Courtenay and Peter Finch. Negative.
Adrian Pasdar is excellent is this film. He makes a fascinating woman. Negative.
This is a good film. This is very funny. Yet after this film there were no good Ernest films! Negative.
Add this little gem to your list of holiday regulars. It is<br /><br />sweet, funny, and endearing Negative.

INFO:__main__:Time taken: 592.0051419734955s
INFO:__main__:Time taken: 475.29746198654175s
INFO:__main__:Time per word for 1.5B model: 191.63347065164368 words per second
INFO:__main__:Time per word for 500 model : 238.6884195127731 words per second
INFO:__main__:Performance for 1.5B model:

INFO:sentiment_analysis:              precision    recall  f1-score   support

    negative       0.26      0.36      0.30       250
    positive       0.01      0.01      0.01       250
         the       0.00      0.00      0.00         0

    accuracy                           0.18       500
   macro avg       0.09      0.12      0.10       500
weighted avg       0.14      0.18      0.16       500

INFO:__main__:Performance for 500M model:

INFO:sentiment_analysis:              precision    recall  f1-score   support

       based       0.00      0.00      0.00         0
    negative       0.31      0.26      0.28       250
    positive       0.24      0.19      0.21       250
         the       0.00      0.00      0.00         0

    accuracy                           0.23       500
   macro avg       0.14      0.11      0.12       500
weighted avg       0.27      0.23      0.25       500

INFO:__main__:Rendering confusion matrix for 1.5B model
INFO:__main__:Rendering confusion matrix for 500M model
INFO:__main__:Finished
